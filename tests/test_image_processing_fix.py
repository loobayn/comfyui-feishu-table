#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æµ‹è¯•ä¿®å¤åçš„å›¾ç‰‡å¤„ç†åŠŸèƒ½
éªŒè¯torch.Tensorç±»å‹çš„å¤„ç†æ˜¯å¦æ­£ç¡®
"""

import sys
import os
import tempfile

# æ·»åŠ çˆ¶ç›®å½•åˆ°è·¯å¾„ï¼Œä»¥ä¾¿å¯¼å…¥æ¨¡å—
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from feishu_video_upload_node import FeishuVideoUploadNode

def test_torch_tensor_processing():
    """æµ‹è¯•torch.Tensorç±»å‹çš„å›¾ç‰‡å¤„ç†"""
    
    print("=== æµ‹è¯•torch.Tensorå›¾ç‰‡å¤„ç† ===")
    
    try:
        # å°è¯•å¯¼å…¥torch
        import torch
        import numpy as np
        print("âœ… æˆåŠŸå¯¼å…¥torchå’Œnumpy")
    except ImportError as e:
        print(f"âŒ æ— æ³•å¯¼å…¥torch: {e}")
        print("è¯·ç¡®ä¿å·²å®‰è£…torchåº“")
        return
    
    node = FeishuVideoUploadNode()
    
    # åˆ›å»ºæµ‹è¯•ç”¨çš„torch.Tensor
    print("\n--- åˆ›å»ºæµ‹è¯•torch.Tensor ---")
    
    # æµ‹è¯•æ¡ˆä¾‹1: 3D RGB tensor (height, width, channels)
    print("æµ‹è¯•æ¡ˆä¾‹1: 3D RGB tensor")
    rgb_tensor = torch.randn(512, 512, 3)  # æ¨¡æ‹ŸRGBå›¾åƒ
    rgb_tensor = torch.clamp(rgb_tensor, 0, 1)  # é™åˆ¶åœ¨0-1èŒƒå›´
    print(f"RGB tensorå½¢çŠ¶: {rgb_tensor.shape}")
    print(f"RGB tensoræ•°æ®ç±»å‹: {rgb_tensor.dtype}")
    print(f"RGB tensorå€¼èŒƒå›´: {rgb_tensor.min().item():.3f} - {rgb_tensor.max().item():.3f}")
    
    # æµ‹è¯•æ¡ˆä¾‹2: 4D batch tensor (batch, height, width, channels)
    print("\næµ‹è¯•æ¡ˆä¾‹2: 4D batch tensor")
    batch_tensor = torch.randn(2, 256, 256, 3)  # æ¨¡æ‹Ÿbatchå›¾åƒ
    batch_tensor = torch.clamp(batch_tensor, 0, 1)
    print(f"Batch tensorå½¢çŠ¶: {batch_tensor.shape}")
    print(f"Batch tensoræ•°æ®ç±»å‹: {batch_tensor.dtype}")
    
    # æµ‹è¯•æ¡ˆä¾‹3: 2D grayscale tensor (height, width)
    print("\næµ‹è¯•æ¡ˆä¾‹3: 2D grayscale tensor")
    gray_tensor = torch.randn(128, 128)  # æ¨¡æ‹Ÿç°åº¦å›¾åƒ
    gray_tensor = torch.clamp(gray_tensor, 0, 1)
    print(f"Grayscale tensorå½¢çŠ¶: {gray_tensor.shape}")
    print(f"Grayscale tensoræ•°æ®ç±»å‹: {gray_tensor.dtype}")
    
    # æµ‹è¯•æ¡ˆä¾‹4: RGBA tensor (height, width, 4)
    print("\næµ‹è¯•æ¡ˆä¾‹4: RGBA tensor")
    rgba_tensor = torch.randn(64, 64, 4)  # æ¨¡æ‹ŸRGBAå›¾åƒ
    rgba_tensor = torch.clamp(rgba_tensor, 0, 1)
    print(f"RGBA tensorå½¢çŠ¶: {rgba_tensor.shape}")
    print(f"RGBA tensoræ•°æ®ç±»å‹: {rgba_tensor.dtype}")
    
    # æµ‹è¯•å›¾ç‰‡å¤„ç†é€»è¾‘
    print("\n--- æµ‹è¯•å›¾ç‰‡å¤„ç†é€»è¾‘ ---")
    
    test_cases = [
        ("RGB tensor", rgb_tensor),
        ("Batch tensor", batch_tensor),
        ("Grayscale tensor", gray_tensor),
        ("RGBA tensor", rgba_tensor),
    ]
    
    for case_name, test_tensor in test_cases:
        print(f"\nå¤„ç†: {case_name}")
        try:
            # æ£€æŸ¥æ˜¯å¦æœ‰numpyæ–¹æ³•
            if hasattr(test_tensor, 'numpy') and callable(test_tensor.numpy):
                print(f"  âœ… æ£€æµ‹åˆ°numpyæ–¹æ³•")
                
                # è½¬æ¢ä¸ºnumpyæ•°ç»„
                if hasattr(test_tensor, 'is_cuda') and test_tensor.is_cuda:
                    test_tensor = test_tensor.cpu()
                    print(f"  âœ… å·²ç§»åŠ¨åˆ°CPU")
                
                numpy_array = test_tensor.numpy()
                print(f"  âœ… è½¬æ¢ä¸ºnumpyæ•°ç»„ï¼Œå½¢çŠ¶: {numpy_array.shape}")
                
                # å¤„ç†ä¸åŒçš„tensorå½¢çŠ¶
                if len(numpy_array.shape) == 4:  # (batch, height, width, channels)
                    numpy_array = numpy_array[0]  # å–ç¬¬ä¸€ä¸ªbatch
                    print(f"  âœ… å–ç¬¬ä¸€ä¸ªbatchï¼Œæ–°å½¢çŠ¶: {numpy_array.shape}")
                elif len(numpy_array.shape) == 3:  # (height, width, channels)
                    pass  # ç›´æ¥ä½¿ç”¨
                elif len(numpy_array.shape) == 2:  # (height, width) - ç°åº¦å›¾
                    numpy_array = np.stack([numpy_array] * 3, axis=-1)  # è½¬æ¢ä¸ºRGB
                    print(f"  âœ… è½¬æ¢ä¸ºRGBï¼Œæ–°å½¢çŠ¶: {numpy_array.shape}")
                
                # ç¡®ä¿æ˜¯3é€šé“RGB
                if numpy_array.shape[-1] == 4:  # RGBA
                    numpy_array = numpy_array[:, :, :3]  # è½¬æ¢ä¸ºRGB
                    print(f"  âœ… è½¬æ¢ä¸ºRGBï¼Œæ–°å½¢çŠ¶: {numpy_array.shape}")
                elif numpy_array.shape[-1] == 1:  # å•é€šé“
                    numpy_array = np.stack([numpy_array[:, :, 0]] * 3, axis=-1)  # è½¬æ¢ä¸º3é€šé“
                    print(f"  âœ… è½¬æ¢ä¸º3é€šé“ï¼Œæ–°å½¢çŠ¶: {numpy_array.shape}")
                
                # ç¡®ä¿å€¼åœ¨0-255èŒƒå›´å†…
                if numpy_array.dtype == np.float32 or numpy_array.dtype == np.float64:
                    if numpy_array.max() <= 1.0:
                        numpy_array = (numpy_array * 255).astype(np.uint8)
                        print(f"  âœ… å€¼èŒƒå›´ä»0-1è½¬æ¢ä¸º0-255")
                    else:
                        numpy_array = numpy_array.astype(np.uint8)
                        print(f"  âœ… å€¼èŒƒå›´å·²è½¬æ¢ä¸º0-255")
                elif numpy_array.dtype != np.uint8:
                    numpy_array = numpy_array.astype(np.uint8)
                    print(f"  âœ… æ•°æ®ç±»å‹è½¬æ¢ä¸ºuint8")
                
                print(f"  âœ… æœ€ç»ˆæ•°ç»„å½¢çŠ¶: {numpy_array.shape}")
                print(f"  âœ… æœ€ç»ˆæ•°æ®ç±»å‹: {numpy_array.dtype}")
                print(f"  âœ… å€¼èŒƒå›´: {numpy_array.min()} - {numpy_array.max()}")
                
                # æ¨¡æ‹Ÿè½¬æ¢ä¸ºPIL Imageå’Œå­—èŠ‚æ•°æ®
                try:
                    from PIL import Image
                    pil_image = Image.fromarray(numpy_array)
                    print(f"  âœ… æˆåŠŸåˆ›å»ºPIL Imageï¼Œæ¨¡å¼: {pil_image.mode}")
                    
                    # æ¨¡æ‹Ÿä¿å­˜ä¸ºJPEG
                    import io
                    buffer = io.BytesIO()
                    pil_image.save(buffer, format='JPEG', quality=95)
                    image_bytes = buffer.getvalue()
                    buffer.close()
                    print(f"  âœ… æˆåŠŸè½¬æ¢ä¸ºJPEGå­—èŠ‚æ•°æ®ï¼Œå¤§å°: {len(image_bytes)} å­—èŠ‚")
                    
                except Exception as e:
                    print(f"  âŒ PILè½¬æ¢å¤±è´¥: {e}")
                
            else:
                print(f"  âŒ æ²¡æœ‰numpyæ–¹æ³•")
                
        except Exception as e:
            print(f"  âŒ å¤„ç†å¤±è´¥: {str(e)}")
            import traceback
            traceback.print_exc()
    
    print("\n=== æµ‹è¯•å®Œæˆ ===")

def test_process_image_data_method():
    """æµ‹è¯•process_image_dataæ–¹æ³•"""
    
    print("\n=== æµ‹è¯•process_image_dataæ–¹æ³• ===")
    
    try:
        import torch
        import numpy as np
        print("âœ… æˆåŠŸå¯¼å…¥torchå’Œnumpy")
    except ImportError as e:
        print(f"âŒ æ— æ³•å¯¼å…¥torch: {e}")
        return
    
    node = FeishuVideoUploadNode()
    
    # åˆ›å»ºæµ‹è¯•tensor
    test_tensor = torch.randn(256, 256, 3)
    test_tensor = torch.clamp(test_tensor, 0, 1)
    print(f"åˆ›å»ºæµ‹è¯•tensor: {test_tensor.shape}, {test_tensor.dtype}")
    
    try:
        # è°ƒç”¨process_image_dataæ–¹æ³•
        print("è°ƒç”¨process_image_dataæ–¹æ³•...")
        result = node.process_image_data(test_tensor)
        
        if result[0] is not None:
            image_data, file_name = result
            print(f"âœ… å¤„ç†æˆåŠŸï¼")
            print(f"  æ–‡ä»¶å: {file_name}")
            print(f"  æ•°æ®å¤§å°: {len(image_data)} å­—èŠ‚")
        else:
            print(f"âŒ å¤„ç†å¤±è´¥: {result[1]}")
            
    except Exception as e:
        print(f"âŒ è°ƒç”¨æ–¹æ³•æ—¶å‘ç”Ÿå¼‚å¸¸: {str(e)}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    test_torch_tensor_processing()
    test_process_image_data_method()
    print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•å®Œæˆï¼")
    print("\nğŸ“ ä¸‹ä¸€æ­¥ï¼š")
    print("1. åœ¨ComfyUIä¸­æµ‹è¯•ä¿®å¤åçš„å›¾ç‰‡ä¸Šä¼ åŠŸèƒ½")
    print("2. éªŒè¯torch.Tensorç±»å‹çš„å›¾ç‰‡å¤„ç†")
    print("3. æ£€æŸ¥å›¾ç‰‡ä¸Šä¼ åˆ°é£ä¹¦å¤šç»´è¡¨æ ¼")

